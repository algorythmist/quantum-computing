{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f9067cf",
   "metadata": {},
   "source": [
    "#### Define bras, kets, brackets\n",
    "$\n",
    "\\newcommand{\\ket}[1]{\\left|{#1}\\right\\rangle}\n",
    "\\newcommand{\\bra}[1]{\\left\\langle{#1}\\right|}\n",
    "\\newcommand{\\braket}[2]{\\left\\langle{#1}\\middle|{#2}\\right\\rangle}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3abca3f",
   "metadata": {},
   "source": [
    "# Highlights\n",
    "\n",
    "### Operators\n",
    "\n",
    "- Hermitian $A^\\dagger = A$ has real eigenvalues\n",
    "\n",
    "- Unitary $U^\\dagger U = UU^\\dagger = I$ has eigenvalues on the unit circle\n",
    "\n",
    "- Projection/Projector $P^2 = P$ has eigenvalues 0 and 1\n",
    "\n",
    "- Positive $\\braket{v}{Av} \\geq 0 (real)$ for all $\\ket{v}$ \n",
    "\n",
    "- Normal $N^\\dagger N = NN^\\dagger$\n",
    "\n",
    "### Spectral decomposition\n",
    "\n",
    "Theorem: The eigenvectors $\\{e_i\\}$ of a normal operator N form a complete orthonormal set and the operator can by decomposed as $N = \\lambda_i \\ket{e_i}\\bra{e_i}$. Since Hermitian, Unitary, and Positive operators are normal, this is true for them as well.\n",
    "\n",
    "Resolution of the identity: $I = \\sum_i \\ket{e_i}\\bra{e_i}$\n",
    "\n",
    "### Polar Decomposition\n",
    "\n",
    "Theorem: Let A be a linear operator on a vector space V. Then there exists a unitary operator U and positive operators J and K such that $A = UJ = KU$, where J and K are given by $J = \\sqrt{A^\\dagger A}$ and $K = \\sqrt{AA^\\dagger}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d35dda",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition\n",
    "\n",
    "Theorem: For any square matrix A, there exist unitary matrices U and V, and a diagonal matrix D with non-negative entries such that $ A = UDV$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c794641",
   "metadata": {},
   "source": [
    "### Bell States\n",
    "\n",
    "$$\n",
    "\\frac{\\ket{00} \\pm \\ket{11}}{\\sqrt{2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\ket{01} \\pm \\ket{10}}{\\sqrt{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dfe758",
   "metadata": {},
   "source": [
    "## Density Matrix\n",
    "\n",
    "### Composite systems\n",
    "\n",
    "#### Partial Trace\n",
    "\n",
    "Let $\\ket{a_1},\\ket{a_2} \\in H_A$, $\\ket{b_1}, \\ket{b_2} \\in H_B$, then \n",
    "\n",
    "$$\n",
    "tr_B\\left(\\ket{a_1}\\bra{a_2}\\otimes \\ket{b_1}\\bra{b_2}\\right) \\equiv \\ket{a_1}\\bra{a_2}tr\\left(\\ket{b_1}\\bra{b_2}\\right)\n",
    "= \\braket{b_2}{b_1}\\left(\\ket{a_1}\\bra{a_2}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7467a0",
   "metadata": {},
   "source": [
    "#### Schmidt Decomposition\n",
    "\n",
    "Theorem: If $\\psi$ is a pure state of a composite system AB, then there exist orthonormal states $i^A$ in A and $i^B$ in B, and non-negative real numbers $\\lambda_i$, such that \n",
    "\n",
    "$$\n",
    "\\ket{\\psi} = \\sum_i \\lambda_i\\ket{i^a}\\ket{i^B}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7973964e",
   "metadata": {},
   "source": [
    "#### Purification\n",
    "\n",
    "Given a possibly mixed state $\\rho^A$, we can introduce a system $R$ of the same dimension as A, such that $\\rho^A$ is the partial trace of a pure state in the combined system.\n",
    "\n",
    "In particular, suppose $\\rho^A = \\sum_i p_i \\ket{i^A}\\bra{i^A}$ and choose an orthonormal basis $i^R$ in R. Define\n",
    "\n",
    "$$\n",
    "\\ket{AR} = \\sum_i \\sqrt{p_i}\\ket{i^A}\\ket{i^R}\n",
    "$$\n",
    "\n",
    "Then $tr_R(\\ket{AR}\\bra{AR}) = \\rho^A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda72938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06e6ff4",
   "metadata": {},
   "source": [
    "### Exercise 2.1\n",
    "\n",
    "Any 3 vectors in 2 dimensions are linearly dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63d0d2",
   "metadata": {},
   "source": [
    "### Exercise 2.2\n",
    "\n",
    "\n",
    "The representation of A in the $\\ket{0},\\ket{1}$ basis is \n",
    "$\\begin{bmatrix}\n",
    "0 &1\\\\1 &0 \n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "For the basis $e_1 = \\ket{0}+\\ket{1}, e_2 = \\ket{0}-\\ket{1}$ (with appropriate normalization), we have\n",
    "\n",
    "$\n",
    "Ae_1 = A(\\ket{0}+\\ket{1}) = \\ket{1}+\\ket{0} = e_1\\\\\n",
    "Ae_2 = A(\\ket{0}-\\ket{1}) = \\ket{1}-\\ket{0} = -e_2\n",
    "$\n",
    "\n",
    "So in this representation $A = \\begin{bmatrix}\n",
    "1 &0\\\\0 & -1 \n",
    "\\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a650ab",
   "metadata": {},
   "source": [
    "### Exercise 2.6\n",
    "\n",
    "$(au, v) = (v,au)^* = (a(v,u))^* = a^*(v,u)^* = a^*(u,v)$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2770fef6",
   "metadata": {},
   "source": [
    "### Exercise 2.8 \n",
    "\n",
    "The Gram-Schmidt process can be established by induction. See for example, https://en.wikipedia.org/wiki/Gramâ€“Schmidt_process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32248fa",
   "metadata": {},
   "source": [
    "### Exercise 2.9 \n",
    "\n",
    "$$\n",
    "\\sigma_i = \\bra{0}\\sigma_i\\ket{0}\\ket{0}\\bra{0} +\n",
    " \\bra{0}\\sigma_i\\ket{1}\\ket{0}\\bra{1} + \n",
    " \\bra{1}\\sigma_i\\ket{0}\\ket{1}\\bra{0} +\n",
    "  \\bra{1}\\sigma_i\\ket{1}\\ket{1}\\bra{1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_0 = \\ket{0}\\bra{0} + \\ket{1}\\bra{1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_1 = \\sigma_X = X = \\ket{0}\\bra{1} + \\ket{1}\\bra{0}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_2 = \\sigma_Y = Y = i \\left(\\ket{1}\\bra{0} - \\ket{0}\\bra{1}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_3 = \\sigma_Z = Z = \\ket{0}\\bra{0} - \\ket{1}\\bra{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30ccb57",
   "metadata": {},
   "source": [
    "### Exercise 2.10\n",
    "\n",
    "The matrix is 1 in position (j,k) and 0 elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e8767",
   "metadata": {},
   "source": [
    "### Exercise 2.11\n",
    "\n",
    "Find the eigenvectors, eigenvalues, and diagonal representations of the Pauli Matrices.\n",
    "\n",
    "I solve this computationally with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d37fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.matrix([[0, 1], [1, 0]])\n",
    "Y = np.matrix([[0, -1j], [1j, 0]])\n",
    "Z = np.matrix([[1, 0], [0, -1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81d7764e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1., -1.]),\n",
       " matrix([[ 0.70710678, -0.70710678],\n",
       "         [ 0.70710678,  0.70710678]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.eig(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c38e6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.,  0.],\n",
       "        [ 0., -1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l, U = la.eig(X)\n",
    "\n",
    "np.round(U.H*X*U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d5e7cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.+0.j, -1.+0.j]),\n",
       " matrix([[-0.        -0.70710678j,  0.70710678+0.j        ],\n",
       "         [ 0.70710678+0.j        ,  0.        -0.70710678j]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.eig(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "626cf7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.+0.j,  0.+0.j],\n",
       "        [ 0.-0.j, -1.+0.j]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l, U = la.eig(Y)\n",
    "\n",
    "np.round(U.H*Y*U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d53ec12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1., -1.]),\n",
       " matrix([[1., 0.],\n",
       "         [0., 1.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.eig(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a367b94",
   "metadata": {},
   "source": [
    "### Problem 2.12\n",
    "\n",
    "The matrix has only one eigenvector $(0, 1)^T$ therefore it cannot be diagonalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2695187",
   "metadata": {},
   "source": [
    "### Exercise 2.16\n",
    "\n",
    "$$\n",
    "P^2 = \\sum_i \\ket{i}\\bra{i} \\sum_j \\ket{j}\\bra{j} =\\\\\n",
    "\\sum_i\\sum_j \\ket{i}\\braket{i}{j}\\bra{j} = \\\\\n",
    "\\sum_i\\sum_j \\delta_{ij}\\ket{i}\\bra{j} = \\\\\n",
    "\\sum_i \\ket{i}\\bra{i} = P\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10311380",
   "metadata": {},
   "source": [
    "### Exercise 2.17\n",
    "\n",
    "The easiest way to show it is via spectral decomposition.\n",
    "Suppose the normal operator $A$ has real eigenvalues and spectral decomposition\n",
    "\n",
    "$A = \\sum a_i \\ket{i}\\bra{i}$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "A^\\dagger = \\sum a^*_i (\\ket{i}\\bra{i})^\\dagger = \\sum a_i \\ket{i}\\bra{i} = A\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a6099",
   "metadata": {},
   "source": [
    "### Exercise 2.18\n",
    "\n",
    "$U\\ket{x} = \\lambda\\ket{x} \\implies \\bra{x}U^\\dagger = \\lambda^*\\bra{x}$\n",
    "\n",
    "combining the two\n",
    "\n",
    "$\\bra{x}U^\\dagger U\\ket{x} = |\\lambda|^2\\braket{x}{x} \\implies \\braket{x}{x} =  |\\lambda|^2\\braket{x}{x} $\n",
    "\n",
    "from which we conclude $|\\lambda|^2 = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bf7686",
   "metadata": {},
   "source": [
    "### Exercise 2.22\n",
    "\n",
    "Using inner product notation\n",
    "$$\n",
    "(v_1, Hv_2) = (Hv_1,v_2) \\implies\\\\\n",
    "\\lambda_2(v_1,v_2) = \\lambda_1(v_1,v_2)\n",
    "$$\n",
    "\n",
    "Since the lambdas ae distinct, we must have $(v_1,v_2) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f950c7a5",
   "metadata": {},
   "source": [
    "### Exercise 2.23\n",
    "\n",
    "$P\\ket{x} = \\lambda x \\implies P^2 \\ket{x} = \\lambda^2 \\ket{x}$ but also $P^2 \\ket{x} =  \\lambda \\ket{x}$, so it has to be $\\lambda = \\lambda^2$ which means it is either 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a252c",
   "metadata": {},
   "source": [
    "### Exercise 2.24\n",
    "\n",
    "Let $B = \\frac{A+A^\\dagger}{2}$, $C = -i\\frac{A-A^\\dagger}{2}$. Then $A = B+iC$.\n",
    "\n",
    "Since $A$ is positive, $\\bra{x}A\\ket{x}$ is real for every $x$, so $\\bra{x}B\\ket{x}+i\\bra{x}C\\ket{x}$ is real. But since $B,C$ are Hermitian, $\\bra{x}B\\ket{x}$ and $\\bra{x}C\\ket{x}$ are real. This means that $C = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7396a",
   "metadata": {},
   "source": [
    "### Exercise 2.25\n",
    "\n",
    "$$\n",
    "\\bra{v}A^\\dagger A\\ket{v} = \\braket{Av}{Av} = ||Av||^2 \\geq 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bacef7",
   "metadata": {},
   "source": [
    "### Exercise 2.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87848ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0,  0,  1,  0],\n",
       "        [ 0,  0,  0, -1],\n",
       "        [ 1,  0,  0,  0],\n",
       "        [ 0, -1,  0,  0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.kron(X,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0af46c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = np.eye(2)\n",
    "np.kron(I,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baa3ab58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.kron(X,I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e335f1",
   "metadata": {},
   "source": [
    "### Exercise 2.29\n",
    "\n",
    "$$\n",
    "(U\\otimes U')^\\dagger (U\\otimes U') (\\ket{x}\\otimes\\ket{y}) = \\\\\n",
    "(U^\\dagger \\otimes U'^\\dagger)(\\ket{Ux}\\otimes\\ket{U'y}) = \\\\\n",
    "(\\ket{U^\\dagger Ux}\\otimes\\ket{ U'^\\dagger U'y}) = \\\\\n",
    "\\ket{x}\\otimes\\ket{y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e6292f",
   "metadata": {},
   "source": [
    "### Execise 2.30\n",
    "\n",
    "This follows directly from the last part of exercise 2.28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dcb178",
   "metadata": {},
   "source": [
    "### Exercise 2.33\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60478b9c",
   "metadata": {},
   "source": [
    "### Exercise 2.34\n",
    "\n",
    "The matrix has eignevalue 7 with eigenvector $[1,1]/\\sqrt(2)$ and 1 with eigenvector  $[1,-1]/\\sqrt(2)$.\n",
    "\n",
    "We have \n",
    "$$\n",
    "[1,1]/\\sqrt(2)\\otimes [1,1]/\\sqrt(2) = \\frac{1}{2}\n",
    "\\begin{bmatrix} 1 &1\\\\ 1 & 1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "[1,-1]/\\sqrt(2)\\otimes [1,-1]/\\sqrt(2) = \\frac{1}{2}\n",
    "\\begin{bmatrix} 1 & -1\\\\ -1 & 1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "so\n",
    "\n",
    "$$\n",
    "f(A) = \\frac{1}{2}\\begin{bmatrix} \n",
    "f(7)+f(1) & f(7)-f(1)\\\\ \n",
    " f(7)-f(1) & f(7)+f(1)\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7352f7c1",
   "metadata": {},
   "source": [
    "### Exercise 2.36\n",
    "\n",
    "By inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5d8fa5",
   "metadata": {},
   "source": [
    "### Exercise 2.37\n",
    "\n",
    "$$\n",
    "tr(AB) = tr(A_i^j B_j^k) = A_i^j B_j^i\n",
    "$$\n",
    "\n",
    "$$\n",
    "tr(BA) = tr(B_i^j A_j^k) = B_i^j A_j^i\n",
    "$$\n",
    "\n",
    "so $tr(AB) = tr(BA)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9971e64",
   "metadata": {},
   "source": [
    "### Exercise 2.39\n",
    "\n",
    "Inner product of operators $(A,B) := tr(A^\\dagger B)$\n",
    "\n",
    "1) We must show the properties of the inner product in section 2.1.4\n",
    "\n",
    "i) $(A,cB)= tr(A^\\dagger cB) = c tr(A^\\dagger B) = c(A,B)$\n",
    "\n",
    "ii) $(A,B)^* = tr(A^\\dagger B)^* = tr(B^\\dagger A) = (B, A)$\n",
    "\n",
    "ii) $(A,A) = tr(A^\\dagger A) = \\sum_i |a_i|^2 \\geq 0$ with equality if all the eigenvalues are 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d540763b",
   "metadata": {},
   "source": [
    "### Exercise 2.41\n",
    "\n",
    "show $\\{\\sigma_i, \\sigma_j \\} = I\\delta_{ij}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27c6432",
   "metadata": {},
   "source": [
    "### Exercise 2.42\n",
    "\n",
    "Show $$AB = \\frac{[A,B] + \\{A,B\\}}{2}$$\n",
    "\n",
    "$$\n",
    "[A,B] + \\{A,B\\} = AB-BA+AB+BA = 2AB\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc96afd7",
   "metadata": {},
   "source": [
    "### Exercise 2.47\n",
    "\n",
    "$$\n",
    "(-i[A,B])^\\dagger = i(AB-BA)^\\dagger = i(B^\\dagger A^\\dagger - A^\\dagger B^\\dagger) = i(BA-AB) = -i(AB-BA) = -i[A,B]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a8f28",
   "metadata": {},
   "source": [
    "### Exercise 2.48\n",
    "\n",
    "The polar decomposition of $A$ is $A = UJ = KU$, where $U$ is unitary and $j,K$ positive.\n",
    "\n",
    "- If $A$ is positive, then $J= K = A$ and $U = I$ \n",
    "- If $A$ is unitary, $U = A$ and $J = K = I$\n",
    "- If $A$ is Hermitian, then $J = K = H$ and $U = I$, because every Hermitian matrix is positive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a8197",
   "metadata": {},
   "source": [
    "### Exercise 2.49\n",
    "\n",
    "If $N$ is normal is has a representation $N = \\sum_i \\lambda_i \\ket{i}\\bra{i}$.\n",
    "\n",
    "$$\n",
    "N^\\dagger N = \\sum_i \\lambda_i \\ket{i}\\bra{i} \\sum_j \\lambda_j^* \\ket{j}\\bra{j} =\n",
    "\\sum_{ij} \\lambda_i \\lambda_j^* \\ket{i}\\braket{i}{j}\\bra{j} = \\sum_i | \\lambda_i|^2 \\ket{i}\\bra{i}\n",
    "$$\n",
    "\n",
    "so $J = \\sqrt(N^\\dagger N) =  \\sum_i | \\lambda_i| \\ket{i}\\bra{i}$\n",
    "\n",
    "Let $U := \\sum_i e^{i\\theta_i}  \\ket{i}\\bra{i}$, where $\\theta_i = arg(\\lambda_i)$\\\n",
    "\n",
    "Then $N = UJ$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994508ae",
   "metadata": {},
   "source": [
    "### Exercise 2.50\n",
    "\n",
    "$\n",
    "A^\\dagger = \\begin{bmatrix}1 & 1\\\\0 & 1\\end{bmatrix}$\n",
    "\n",
    "$$\n",
    "A^\\dagger A = \\begin{bmatrix}1 & 1\\\\0 & 1\\end{bmatrix}\\begin{bmatrix}1 & 0\\\\1 & 1\\end{bmatrix} \n",
    "= \\begin{bmatrix} 2 & 1\\\\1 & 1\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "$$\n",
    "AA^\\dagger = \\begin{bmatrix}1 & 0\\\\1 & 1\\end{bmatrix}\\begin{bmatrix}1 & 1\\\\0 & 1\\end{bmatrix}\n",
    "= \\begin{bmatrix}1 & 1\\\\1 & 2\\end{bmatrix} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28778a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.34164079, 0.4472136 ],\n",
       "        [0.4472136 , 0.89442719]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalues, evectors = np.linalg.eig(np.matrix([[2, 1], [1,1]]))\n",
    "J = evectors @ np.diag(np.sqrt(evalues)) @ np.linalg.inv(evectors)\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82a8dfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.89442719, 0.4472136 ],\n",
       "        [0.4472136 , 1.34164079]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalues, evectors = np.linalg.eig(np.matrix([[1, 1], [1,2]]))\n",
    "K = evectors @ np.diag(np.sqrt(evalues)) @ np.linalg.inv(evectors)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd5c6b3",
   "metadata": {},
   "source": [
    "TODO: Find U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d0d44",
   "metadata": {},
   "source": [
    "### Exercises 2.51-2.53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3600e28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.70710678,  0.70710678],\n",
       "        [ 0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "H = np.matrix([[1, 1], [1, -1]]) / np.sqrt(2)\n",
    "H.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39e888a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1., -0.],\n",
       "        [-0.,  1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(H**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0185682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1., -1.]),\n",
       " matrix([[ 0.92387953, -0.38268343],\n",
       "         [ 0.38268343,  0.92387953]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.eig(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dcb4e8",
   "metadata": {},
   "source": [
    "### Exercise 2.54\n",
    "\n",
    "Since A and B commute, there is a unitary matrix U such that \n",
    "$U^\\dagger A U = diag(a_1, \\ldots, a_n)$ and $U^\\dagger B U = diag(b_1, \\ldots, b_n)$.\n",
    "\n",
    "Therefore\n",
    "\n",
    "$$\n",
    "exp(A)exp(B) = U^\\dagger diag(e^a_i) diag(e^b_i) U = U^\\dagger diag(e^{a_i + b_i}) U = exp(A+B)$ \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9df7077",
   "metadata": {},
   "source": [
    "### Exercise 2.57\n",
    "\n",
    "Just apply 2.92 and 2.93 twice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79932656",
   "metadata": {},
   "source": [
    "### Exercise 2.58\n",
    "\n",
    "The expectation is the eigenvalue corresponding to $\\psi$ and the variance is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3fad8b",
   "metadata": {},
   "source": [
    "### Exercise 2.59\n",
    "\n",
    "$E[X] = \\bra{0}X\\ket{0} = \\braket{0}{1} = 0$\n",
    "\n",
    "$std(X) = \\left(\\bra{0}X^2\\ket{0} - E[X]^2\\right)^\\frac{1}{2} = 1$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25dbbe",
   "metadata": {},
   "source": [
    "### Exercise 2.60\n",
    "\n",
    "Let $\\Sigma := \\sum_{i=1}^3 v_i \\sigma_i := v\\cdot\\sigma$\n",
    "\n",
    "1) To show the eigenvalues are $\\pm 1$ it suffices to show $\\Sigma^2 = I$\n",
    "\n",
    "$$\n",
    "\\Sigma^2 = \\sum_{ij}v_i v_j \\sigma_i \\sigma_j = \\sum_i v_i^2 \\sigma_i^2 + \\sum_{i\\neq j}v_i v_j \\sigma_i \\sigma_j = \n",
    "\\sum_i v_i^2 + \\sum_{i\\neq j} \\epsilon_{ij}^k\\sigma_k\n",
    "$$\n",
    "\n",
    "The first terms sums to the identity since v is a unit vector and the second term cancels out, so $\\Sigma^2 = I$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d1e054",
   "metadata": {},
   "source": [
    "2) To show that P is a projector we must show $P^2 = P$.\n",
    "\n",
    "$$\n",
    "P^2 = \\frac{1}{4}(I+\\sum_i v_i \\sigma_i)(I+\\sum_j v_j \\sigma_j) = \n",
    " \\frac{1}{4}\\left(I + 2\\sum_i v_i \\sigma_i + \\sum_{i} v_i^2 +  \\sum_{i\\neq j} \\epsilon_{ij}^k\\sigma_k \\right) =\\\\\n",
    " \\frac{1}{4}\\left(2I + 2 v\\cdot\\sigma \\right) = \\frac{I + v\\cdot\\sigma}{2} = P\n",
    "$$\n",
    "\n",
    "The calculation for the minus sign version is the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ab4aef",
   "metadata": {},
   "source": [
    "3) To show thet P projects on the eigenspace spanned by the eigenvectors, it suffices to show that every eigenvector is projected onto the same subspace.\n",
    "\n",
    "let $\\ket{x}$ be an eigenvector of $\\Sigma$ with eigenvalue 1\n",
    "\n",
    "$$\n",
    "(I+\\Sigma)\\ket{x} = 2\\ket{x}\n",
    "$$\n",
    "\n",
    "so it is in the same subspace. The same result follows for the the other projector and an eigenvector of -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91503dbc",
   "metadata": {},
   "source": [
    "### Exercise 2.61\n",
    "\n",
    "VERIFY\n",
    "\n",
    "Probability = ${1+v_3}{2}$\n",
    "\n",
    "State = $(1+v_3)\\ket{0} + (v_1+iv_2)\\ket{1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aadccc9",
   "metadata": {},
   "source": [
    "### Exercise 2.62\n",
    "\n",
    "If $M_m = E_m$, then $M_m = M_m^\\dagger M_m$.\n",
    "\n",
    "Taking the transpose of both sides\n",
    "\n",
    "$M_m^\\dagger = M_m^\\dagger M_m = M_m$\n",
    "\n",
    "from which we conclude $M_m^2 = M_m$, therefore it is a projection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48816c",
   "metadata": {},
   "source": [
    "### Exercise 2.65\n",
    "\n",
    "Apply H to these states to get $\\ket{1}$ and $\\ket{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28acdbe4",
   "metadata": {},
   "source": [
    "### Exercise 2.66\n",
    "\n",
    "$X_1 Z_2\\ket{00} = \\ket{10}$\n",
    "$X_1 Z_2\\ket{11} = -\\ket{01}$\n",
    "\n",
    "so $X_1 Z_2\\ket{\\psi} = \\frac{\\ket{10}-\\ket{01}}{\\sqrt{2}}$\n",
    "\n",
    "and since Bell states are orthonormal the inner product of this with $\\psi$ is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ca829",
   "metadata": {},
   "source": [
    "### Exercise 2.67\n",
    "\n",
    "The idea is to extend the $m \\times m$ matrix $U$ to an $n \\times n$ matrix \n",
    "$\\begin{bmatrix}U & 0\\\\ 0 & I\\end{bmatrix}$\n",
    "\n",
    "First, start by choosing an orthonormal basis $e_1, \\ldots, e_n$ such that $e_1, \\ldots, e_m$ are in $W$ and the remaining are in $W^\\perp$.\n",
    "\n",
    "Then note that the images $\\epsilon_j = Ue_j$ are also orthonormal by the inner product preserving property of $U$:\n",
    "$\\braket{\\epsilon_i}{\\epsilon_j} = \\braket{Ue_i}{Ue_j} \\braket{e_i}{e_j} = \\delta_{ij}$ \n",
    "\n",
    "Using the Gram-Schmidt process extend $\\epsilon_1, \\ldots \\epsilon_m$ to a full orthonormal basis that spans $Im(U)^\\perp$.\n",
    "\n",
    "The for a vector $v = \\sum_i v^i e_i$, define $U'v \\equiv \\sum_i v^i \\epsilon_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4da1a",
   "metadata": {},
   "source": [
    "### Exercise 2.68\n",
    "\n",
    "Let $\\ket{a} = a_1\\ket{0}+a_2\\ket{1}$, $\\ket{b} = b_1\\ket{0}+b_2\\ket{1}$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\ket{a}\\otimes \\ket{b} = ( a_1\\ket{0}+a_2\\ket{1})\\otimes (b_1\\ket{0}+b_2\\ket{1}) =\n",
    "a_1 b_1\\ket{00}+a_2 b_1\\ket{10}+a_1 b_2\\ket{01}+a_2 b_2 \\ket{11}\n",
    "$$\n",
    "\n",
    "So we must have $a_1 b_1 = a_2 b_2 = 1$ and  $a_1 b_2 = a_2 b_1 = 0$, which is impossible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824527be",
   "metadata": {},
   "source": [
    "### Exercise 2.71\n",
    "\n",
    "Note that $tr(\\ket{v}\\bra{w}) = \\braket{w}{v}$.\n",
    "\n",
    "Also, by the Schwartz inequality\n",
    "\n",
    "$\n",
    "|\\braket{v}{w}|^2 \\leq |v|^2|w|^2\n",
    "$\n",
    "\n",
    "so for normalized vectors\n",
    "\n",
    "$\n",
    "|\\braket{v}{w}|^2 \\leq 1\n",
    "$\n",
    "\n",
    "$$\n",
    "\\rho^2 = \\sum_i p_i \\ket{x_i}\\bra{x_i}\\sum_j p_j \\ket{x_j}\\bra{x_j} =\n",
    "\\sum_{ij} p_i p_j \\braket{x_i}{x_j}\\ket{x_i}\\bra{x_j}\n",
    "$$\n",
    "\n",
    "$$\n",
    "tr(\\rho^2) = \\sum_{ij} p_i p_j \\braket{x_i}{x_j} tr(\\ket{x_i}\\bra{x_j}) =  \n",
    "\\sum_{ij} p_i p_j \\braket{x_i}{x_j} \\braket{x_j}{x_i}=\\\\\n",
    "\\sum_{ij} p_i p_j |\\braket{x_i}{x_j}|^2 \\leq \\sum_{ij} p_i p_j = \\sum_i p_i \\sum_j p_j = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2f1a12",
   "metadata": {},
   "source": [
    "### Exercise 2.72\n",
    "\n",
    "1) We must show that the trace is 1 and the operator is positive\n",
    "\n",
    "$tr(\\rho) = \\frac{tr(I)+ \\sum_i r_i tr(\\sigma_i)}{2} = \\frac{2+0}{2} = 1$\n",
    "\n",
    "To show it is positive, we must show $<v,\\rho v> \\geq 0$ for all v\n",
    "\n",
    "$$\n",
    "<v, \\rho v> = \\frac{1}{2}\\left(|v|^2 + \\sum_i r_i <v_i ,\\sigma_i v_i>\\right)\n",
    "$$\n",
    "\n",
    "Since the $\\sigma_i$ are Hermitian, $<v_i ,\\sigma_i v_i>$ is real. We can use the fact that $|r| \\leq 1$ to show that the expression is positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d07aac1",
   "metadata": {},
   "source": [
    "2. $ r = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b895f3f",
   "metadata": {},
   "source": [
    "3)\n",
    "\n",
    "$$\n",
    "\\rho^2 = \\left(\\frac{I+r^i \\sigma_i}{2}\\right)\\left(\\frac{I+r^j \\sigma_j}{2}\\right)=\\\\\n",
    "\\frac{1}{4}\\left(I + 2r^i \\sigma_i + r^i r^j \\sigma_i \\sigma_j \\right) = \\\\\n",
    "\\frac{1}{4}\\left(I + 2r^i \\sigma_i + \\sum_i (r^i)^2 \\sum_{j \\neq i} r^i r^j e_{ij}^k \\sigma_k \\right)\n",
    "$$\n",
    "\n",
    "Using the fact that $tr(\\sigma_i) = 0$, we have\n",
    "\n",
    "$$\n",
    "tr(\\rho^2) = \\frac{1}{4}(2 + 2|r|^2) = \\frac{1}{2}(1+|r|^2)\n",
    "$$\n",
    "\n",
    "which is 1 iff $|r| = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd20371e",
   "metadata": {},
   "source": [
    "4)  TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7fc8f2",
   "metadata": {},
   "source": [
    "### Exercise 2.73 \n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262a514b",
   "metadata": {},
   "source": [
    "### Exercise 2.74\n",
    "\n",
    "$$\n",
    "\\rho^A = tr_B(\\rho^{AB}) = tr_B(\\ket{a}\\ket{b}\\bra{b}\\bra{a}) = |b|^2\\ket{a}\\bra{a}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0698b7cf",
   "metadata": {},
   "source": [
    "### Exercise 2.75\n",
    "\n",
    "Pick $\\ket{\\psi} = \\frac{\\ket{00} \\pm \\ket{11}}{\\sqrt{2}}$. Then\n",
    "\n",
    "$$\n",
    "\\ket{\\psi}\\bra{\\psi} = \\frac{1}{2}\\left[ \\ket{00}\\bra{00} + \\ket{11}\\bra{11} + \\ket{01}\\bra{01} + \\ket{10}\\bra{10}\\right]  \n",
    "$$\n",
    "\n",
    "$$\n",
    "tr_B(\\ket{\\psi}\\bra{\\psi}) = \\frac{1}{2}\\left[\\ket{0}\\bra{0} + \\ket{1}\\bra{1} \\right]  \n",
    "$$\n",
    "\n",
    "where I have used the orthonormality of 0 and 1 to get rid of the cross-terms. The calculation for the other states is similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d37cdf",
   "metadata": {},
   "source": [
    "### Exercise 2.76\n",
    "\n",
    "The generalization follows from the fact that SVD is possible for non-square matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b31cb",
   "metadata": {},
   "source": [
    "### Exercise 2.78\n",
    "\n",
    "1) Prove that $\\psi$ is a product state iff it has Schmidt number 1.\n",
    "\n",
    "If  $\\ket{\\psi} = \\ket{a}\\ket{b}$  then it has a Schmidt representation $ |a||b|\\ket{a/|a|}\\ket{b/|b|}$ which has rank 1. Conversely, if $\\ket{\\psi}$ has a rank 1  Schmidt representation $\\lambda\\ket{a}\\ket{b}$ then it is clearly a product state.\n",
    "\n",
    "2) Prove that $\\psi$ is a product state iff  $\\rho^A$ (and $\\rho^B)$ are pure states\n",
    "\n",
    "If $\\ket{\\psi} = \\ket{a}\\ket{b}$, then $\\rho = \\ket{a}\\ket{b}\\otimes\\bra{a}\\bra{b}$, so \n",
    "$\\rho^A = |b|^2\\ket{a}\\bra{a}$ which is a pure state (same for $\\rho^B$).\n",
    "\n",
    "If $\\rho^A = \\ket{a}\\bra{a}$ and $\\rho^B = \\ket{b}\\bra{b}$, then \n",
    "$\\rho = \\rho^A \\otimes \\rho^B = \\ket{a}\\ket{b}\\otimes\\bra{a}\\bra{b}$, which is a product state.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum-computing",
   "language": "python",
   "name": "quantum-computing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
