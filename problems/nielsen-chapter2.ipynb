{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f9067cf",
   "metadata": {},
   "source": [
    "#### Define bras, kets, brackets\n",
    "$\n",
    "\\newcommand{\\ket}[1]{\\left|{#1}\\right\\rangle}\n",
    "\\newcommand{\\bra}[1]{\\left\\langle{#1}\\right|}\n",
    "\\newcommand{\\braket}[2]{\\left\\langle{#1}\\middle|{#2}\\right\\rangle}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3abca3f",
   "metadata": {},
   "source": [
    "# Highlights\n",
    "\n",
    "### Operators\n",
    "\n",
    "- Hermitian $A^\\dagger = A$ has real eigenvalues\n",
    "\n",
    "- Unitary $U^\\dagger U = UU^\\dagger = I$ has eigenvalues on the unit circle\n",
    "\n",
    "- Projection/Projector $P^2 = P$ has eigenvalues 0 and 1\n",
    "\n",
    "- Positive $\\braket{v}{Av} \\geq 0 (real)$ for all $\\ket{v}$ \n",
    "\n",
    "- Normal $N^\\dagger N = NN^\\dagger$\n",
    "\n",
    "### Spectral decomposition\n",
    "\n",
    "Theorem: The eigenvectors $\\{e_i\\}$ of a normal operator N form a complete orthonormal set and the operator can by decomposed as $N = \\lambda_i \\ket{e_i}\\bra{e_i}$. Since Hermitian, Unitary, and Positive operators are normal, this is true for them as well.\n",
    "\n",
    "Resolution of the identity: $I = \\sum_i \\ket{e_i}\\bra{e_i}$\n",
    "\n",
    "### Polar Decomposition\n",
    "\n",
    "Theorem: Let A be a linear operator on a vector space V. Then there exists a unitary operator U and positive operators J and K such that $A = UJ = KU$, where J and K are given by $J = \\sqrt{A^\\dagger A}$ and $K = \\sqrt{AA^\\dagger}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d35dda",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition\n",
    "\n",
    "Theorem: For any square matrix A, there exist unitary matrices U and V, and a diagonal matrix D with non-negative entries such that $ A = UDV$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c794641",
   "metadata": {},
   "source": [
    "### Bell States\n",
    "\n",
    "$$\n",
    "\\frac{\\ket{00} \\pm \\ket{11}}{\\sqrt{2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\ket{01} \\pm \\ket{10}}{\\sqrt{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda72938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06e6ff4",
   "metadata": {},
   "source": [
    "### Exercise 2.1\n",
    "\n",
    "Any 3 vectors in 2 dimensions are linearly dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63d0d2",
   "metadata": {},
   "source": [
    "### Exercise 2.2\n",
    "\n",
    "\n",
    "The representation of A in the $\\ket{0},\\ket{1}$ basis is \n",
    "$\\begin{bmatrix}\n",
    "0 &1\\\\1 &0 \n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "For the basis $e_1 = \\ket{0}+\\ket{1}, e_2 = \\ket{0}-\\ket{1}$ (with appropriate normalization), we have\n",
    "\n",
    "$\n",
    "Ae_1 = A(\\ket{0}+\\ket{1}) = \\ket{1}+\\ket{0} = e_1\\\\\n",
    "Ae_2 = A(\\ket{0}-\\ket{1}) = \\ket{1}-\\ket{0} = -e_2\n",
    "$\n",
    "\n",
    "So in this representation $A = \\begin{bmatrix}\n",
    "1 &0\\\\0 & -1 \n",
    "\\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a650ab",
   "metadata": {},
   "source": [
    "### Exercise 2.6\n",
    "\n",
    "$(au, v) = (v,au)^* = (a(v,u))^* = a^*(v,u)^* = a^*(u,v)$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2770fef6",
   "metadata": {},
   "source": [
    "### Exercise 2.8 \n",
    "\n",
    "The Gram-Schmidt process can be established by induction. See for example, https://en.wikipedia.org/wiki/Gramâ€“Schmidt_process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32248fa",
   "metadata": {},
   "source": [
    "### Exercise 2.9 \n",
    "\n",
    "$$\n",
    "\\sigma_i = \\bra{0}\\sigma_i\\ket{0}\\ket{0}\\bra{0} +\n",
    " \\bra{0}\\sigma_i\\ket{1}\\ket{0}\\bra{1} + \n",
    " \\bra{1}\\sigma_i\\ket{0}\\ket{1}\\bra{0} +\n",
    "  \\bra{1}\\sigma_i\\ket{1}\\ket{1}\\bra{1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_0 = \\ket{0}\\bra{0} + \\ket{1}\\bra{1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_1 = \\sigma_X = X = \\ket{0}\\bra{1} + \\ket{1}\\bra{0}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_2 = \\sigma_Y = Y = i \\left(\\ket{1}\\bra{0} - \\ket{0}\\bra{1}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_3 = \\sigma_Z = Z = \\ket{0}\\bra{0} - \\ket{1}\\bra{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30ccb57",
   "metadata": {},
   "source": [
    "### Exercise 2.10\n",
    "\n",
    "The matrix is 1 in position (j,k) and 0 elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e8767",
   "metadata": {},
   "source": [
    "### Exercise 2.11\n",
    "\n",
    "Find the eigenvectors, eigenvalues, and diagonal representations of the Pauli Matrices.\n",
    "\n",
    "I solve this computationally with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d37fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.matrix([[0, 1], [1, 0]])\n",
    "Y = np.matrix([[0, -1j], [1j, 0]])\n",
    "Z = np.matrix([[1, 0], [0, -1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81d7764e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1., -1.]),\n",
       " matrix([[ 0.70710678, -0.70710678],\n",
       "         [ 0.70710678,  0.70710678]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.eig(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c38e6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.,  0.],\n",
       "        [ 0., -1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l, U = la.eig(X)\n",
    "\n",
    "np.round(U.H*X*U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d5e7cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.+0.j, -1.+0.j]),\n",
       " matrix([[-0.        -0.70710678j,  0.70710678+0.j        ],\n",
       "         [ 0.70710678+0.j        ,  0.        -0.70710678j]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.eig(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "626cf7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.+0.j,  0.+0.j],\n",
       "        [ 0.-0.j, -1.+0.j]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l, U = la.eig(Y)\n",
    "\n",
    "np.round(U.H*Y*U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d53ec12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1., -1.]),\n",
       " matrix([[1., 0.],\n",
       "         [0., 1.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.eig(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a367b94",
   "metadata": {},
   "source": [
    "### Problem 2.12\n",
    "\n",
    "The matrix has only one eigenvector $(0, 1)^T$ therefore it cannot be diagonalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2695187",
   "metadata": {},
   "source": [
    "### Exercise 2.16\n",
    "\n",
    "$$\n",
    "P^2 = \\sum_i \\ket{i}\\bra{i} \\sum_j \\ket{j}\\bra{j} =\\\\\n",
    "\\sum_i\\sum_j \\ket{i}\\braket{i}{j}\\bra{j} = \\\\\n",
    "\\sum_i\\sum_j \\delta_{ij}\\ket{i}\\bra{j} = \\\\\n",
    "\\sum_i \\ket{i}\\bra{i} = P\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10311380",
   "metadata": {},
   "source": [
    "### Exercise 2.17\n",
    "\n",
    "The easiest way to show it is via spectral decomposition.\n",
    "Suppose the normal operator $A$ has real eigenvalues and spectral decomposition\n",
    "\n",
    "$A = \\sum a_i \\ket{i}\\bra{i}$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "A^\\dagger = \\sum a^*_i (\\ket{i}\\bra{i})^\\dagger = \\sum a_i \\ket{i}\\bra{i} = A\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a6099",
   "metadata": {},
   "source": [
    "### Exercise 2.18\n",
    "\n",
    "$U\\ket{x} = \\lambda\\ket{x} \\implies \\bra{x}U^\\dagger = \\lambda^*\\bra{x}$\n",
    "\n",
    "combining the two\n",
    "\n",
    "$\\bra{x}U^\\dagger U\\ket{x} = |\\lambda|^2\\braket{x}{x} \\implies \\braket{x}{x} =  |\\lambda|^2\\braket{x}{x} $\n",
    "\n",
    "from which we conclude $|\\lambda|^2 = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bf7686",
   "metadata": {},
   "source": [
    "### Exercise 2.22\n",
    "\n",
    "Using inner product notation\n",
    "$$\n",
    "(v_1, Hv_2) = (Hv_1,v_2) \\implies\\\\\n",
    "\\lambda_2(v_1,v_2) = \\lambda_1(v_1,v_2)\n",
    "$$\n",
    "\n",
    "Since the lambdas ae distinct, we must have $(v_1,v_2) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f950c7a5",
   "metadata": {},
   "source": [
    "### Exercise 2.23\n",
    "\n",
    "$P\\ket{x} = \\lambda x \\implies P^2 \\ket{x} = \\lambda^2 \\ket{x}$ but also $P^2 \\ket{x} =  \\lambda \\ket{x}$, so it has to be $\\lambda = \\lambda^2$ which means it is either 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a252c",
   "metadata": {},
   "source": [
    "### Exercise 2.24\n",
    "\n",
    "Let $B = \\frac{A+A^\\dagger}{2}$, $C = -i\\frac{A-A^\\dagger}{2}$. Then $A = B+iC$.\n",
    "\n",
    "Since $A$ is positive, $\\bra{x}A\\ket{x}$ is real for every $x$, so $\\bra{x}B\\ket{x}+i\\bra{x}C\\ket{x}$ is real. But since $B,C$ are Hermitian, $\\bra{x}B\\ket{x}$ and $\\bra{x}C\\ket{x}$ are real. This means that $C = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7396a",
   "metadata": {},
   "source": [
    "### Exercise 2.25\n",
    "\n",
    "$$\n",
    "\\bra{v}A^\\dagger A\\ket{v} = \\braket{Av}{Av} = ||Av||^2 \\geq 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bacef7",
   "metadata": {},
   "source": [
    "### Exercise 2.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87848ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0,  0,  1,  0],\n",
       "        [ 0,  0,  0, -1],\n",
       "        [ 1,  0,  0,  0],\n",
       "        [ 0, -1,  0,  0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.kron(X,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0af46c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = np.eye(2)\n",
    "np.kron(I,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baa3ab58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.kron(X,I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e335f1",
   "metadata": {},
   "source": [
    "### Exercise 2.29\n",
    "\n",
    "$$\n",
    "(U\\otimes U')^\\dagger (U\\otimes U') (\\ket{x}\\otimes\\ket{y}) = \\\\\n",
    "(U^\\dagger \\otimes U'^\\dagger)(\\ket{Ux}\\otimes\\ket{U'y}) = \\\\\n",
    "(\\ket{U^\\dagger Ux}\\otimes\\ket{ U'^\\dagger U'y}) = \\\\\n",
    "\\ket{x}\\otimes\\ket{y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e6292f",
   "metadata": {},
   "source": [
    "### Execise 2.30\n",
    "\n",
    "This follows directly from the last part of exercise 2.28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dcb178",
   "metadata": {},
   "source": [
    "### Exercise 2.33\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60478b9c",
   "metadata": {},
   "source": [
    "### Exercise 2.34\n",
    "\n",
    "The matrix has eignevalue 7 with eigenvector $[1,1]/\\sqrt(2)$ and 1 with eigenvector  $[1,-1]/\\sqrt(2)$.\n",
    "\n",
    "We have \n",
    "$$\n",
    "[1,1]/\\sqrt(2)\\otimes [1,1]/\\sqrt(2) = \\frac{1}{2}\n",
    "\\begin{bmatrix} 1 &1\\\\ 1 & 1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "[1,-1]/\\sqrt(2)\\otimes [1,-1]/\\sqrt(2) = \\frac{1}{2}\n",
    "\\begin{bmatrix} 1 & -1\\\\ -1 & 1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "so\n",
    "\n",
    "$$\n",
    "f(A) = \\frac{1}{2}\\begin{bmatrix} \n",
    "f(7)+f(1) & f(7)-f(1)\\\\ \n",
    " f(7)-f(1) & f(7)+f(1)\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7352f7c1",
   "metadata": {},
   "source": [
    "### Exercise 2.36\n",
    "\n",
    "By inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5d8fa5",
   "metadata": {},
   "source": [
    "### Exercise 2.37\n",
    "\n",
    "$$\n",
    "tr(AB) = tr(A_i^j B_j^k) = A_i^j B_j^i\n",
    "$$\n",
    "\n",
    "$$\n",
    "tr(BA) = tr(B_i^j A_j^k) = B_i^j A_j^i = A_j^i B_i^j\n",
    "$$\n",
    "\n",
    "so $tr(AB) = tr(BA)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9971e64",
   "metadata": {},
   "source": [
    "### Exercise 2.39\n",
    "\n",
    "Inner product of operators $(A,B) := tr(A^\\dagger B)$\n",
    "\n",
    "1) We must show the properties of the inner product in section 2.1.4\n",
    "\n",
    "i) $(A,cB)= tr(A^\\dagger cB) = c tr(A^\\dagger B) = c(A,B)$\n",
    "\n",
    "ii) $(A,B)^* = tr(A^\\dagger B)^* = tr(B^\\dagger A) = (B, A)$\n",
    "\n",
    "ii) $(A,A) = tr(A^\\dagger A) = \\sum_i |a_i|^2 \\geq 0$ with equality if all the eigenvalues are 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a5e9d",
   "metadata": {},
   "source": [
    "### Exercise 2.40\n",
    "\n",
    "Show \n",
    "\n",
    "$$\n",
    "[\\sigma_j, \\sigma_k] = 2i\\sum_{l=1}^3 \\epsilon_{jkl}\\sigma_l\n",
    "$$\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d540763b",
   "metadata": {},
   "source": [
    "### Exercise 2.41\n",
    "\n",
    "show $\\{\\sigma_i, \\sigma_j \\} = 2 I\\delta_{ij}$\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27c6432",
   "metadata": {},
   "source": [
    "### Exercise 2.42\n",
    "\n",
    "Show $$AB = \\frac{[A,B] + \\{A,B\\}}{2}$$\n",
    "\n",
    "#### Solution\n",
    "\n",
    "$$\n",
    "[A,B] + \\{A,B\\} = AB-BA+AB+BA = 2AB\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c980a17f",
   "metadata": {},
   "source": [
    "### Exercise 2.43\n",
    "\n",
    "Add 2.40 and 2.41\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ab1d53",
   "metadata": {},
   "source": [
    "### Exercise 2.44\n",
    "\n",
    "$[A,B] = 0 \\implies AB = BA$\n",
    "\n",
    "$AB+BA = 0 \\implies 2AB = 0$, which we can multiply from the left with $A^{-1}$ to get $B = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd3fcd3",
   "metadata": {},
   "source": [
    "### Exercise 2.45\n",
    "\n",
    "$$\n",
    "[A,B]^\\dagger = (AB-BA)^\\dagger = B^\\dagger A^\\dagger - A^\\dagger B^\\dagger = \n",
    "[B^\\dagger, A^\\dagger]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f746d6a",
   "metadata": {},
   "source": [
    "### Exercise 2.46\n",
    "\n",
    "$$\n",
    "[A,B] = AB-BA = - (BA-AB) = -[B,A]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc96afd7",
   "metadata": {},
   "source": [
    "### Exercise 2.47\n",
    "\n",
    "$$\n",
    "(-i[A,B])^\\dagger = i(AB-BA)^\\dagger = i(B^\\dagger A^\\dagger - A^\\dagger B^\\dagger) = i(BA-AB) = -i(AB-BA) = -i[A,B]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a8f28",
   "metadata": {},
   "source": [
    "### Exercise 2.48\n",
    "\n",
    "The polar decomposition of $A$ is $A = UJ = KU$, where $U$ is unitary and $j,K$ positive.\n",
    "\n",
    "- If $A$ is positive, then $J= K = A$ and $U = I$ \n",
    "- If $A$ is unitary, $U = A$ and $J = K = I$\n",
    "- If $A$ is Hermitian, then $J = K = H$ and $U = I$, because every Hermitian matrix is positive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a8197",
   "metadata": {},
   "source": [
    "### Exercise 2.49\n",
    "\n",
    "If $N$ is normal is has a representation $N = \\sum_i \\lambda_i \\ket{i}\\bra{i}$.\n",
    "\n",
    "$$\n",
    "N^\\dagger N = \\sum_i \\lambda_i \\ket{i}\\bra{i} \\sum_j \\lambda_j^* \\ket{j}\\bra{j} =\n",
    "\\sum_{ij} \\lambda_i \\lambda_j^* \\ket{i}\\braket{i}{j}\\bra{j} = \\sum_i | \\lambda_i|^2 \\ket{i}\\bra{i}\n",
    "$$\n",
    "\n",
    "so $J = \\sqrt(N^\\dagger N) =  \\sum_i | \\lambda_i| \\ket{i}\\bra{i}$\n",
    "\n",
    "Let $U := \\sum_i e^{i\\theta_i}  \\ket{i}\\bra{i}$, where $\\theta_i = arg(\\lambda_i)$\\\n",
    "\n",
    "Then $N = UJ$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994508ae",
   "metadata": {},
   "source": [
    "### Exercise 2.50\n",
    "\n",
    "$\n",
    "A^\\dagger = \\begin{bmatrix}1 & 1\\\\0 & 1\\end{bmatrix}$\n",
    "\n",
    "$$\n",
    "A^\\dagger A = \\begin{bmatrix}1 & 1\\\\0 & 1\\end{bmatrix}\\begin{bmatrix}1 & 0\\\\1 & 1\\end{bmatrix} \n",
    "= \\begin{bmatrix} 2 & 1\\\\1 & 1\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "$$\n",
    "AA^\\dagger = \\begin{bmatrix}1 & 0\\\\1 & 1\\end{bmatrix}\\begin{bmatrix}1 & 1\\\\0 & 1\\end{bmatrix}\n",
    "= \\begin{bmatrix}1 & 1\\\\1 & 2\\end{bmatrix} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28778a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.34164079, 0.4472136 ],\n",
       "        [0.4472136 , 0.89442719]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalues, evectors = np.linalg.eig(np.matrix([[2, 1], [1,1]]))\n",
    "J = evectors @ np.diag(np.sqrt(evalues)) @ np.linalg.inv(evectors)\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82a8dfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.89442719, 0.4472136 ],\n",
       "        [0.4472136 , 1.34164079]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalues, evectors = np.linalg.eig(np.matrix([[1, 1], [1,2]]))\n",
    "K = evectors @ np.diag(np.sqrt(evalues)) @ np.linalg.inv(evectors)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd5c6b3",
   "metadata": {},
   "source": [
    "TODO: Find U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d0d44",
   "metadata": {},
   "source": [
    "### Exercises 2.51-2.53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3600e28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.70710678,  0.70710678],\n",
       "        [ 0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "H = np.matrix([[1, 1], [1, -1]]) / np.sqrt(2)\n",
    "H.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39e888a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1., -0.],\n",
       "        [-0.,  1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(H**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0185682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1., -1.]),\n",
       " matrix([[ 0.92387953, -0.38268343],\n",
       "         [ 0.38268343,  0.92387953]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.eig(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dcb4e8",
   "metadata": {},
   "source": [
    "### Exercise 2.54\n",
    "\n",
    "Since A and B commute, there is a unitary matrix U such that \n",
    "$U^\\dagger A U = diag(a_1, \\ldots, a_n)$ and $U^\\dagger B U = diag(b_1, \\ldots, b_n)$.\n",
    "\n",
    "Therefore\n",
    "\n",
    "$$\n",
    "exp(A)exp(B) = U^\\dagger diag(e^a_i) diag(e^b_i) U = U^\\dagger diag(e^{a_i + b_i}) U = exp(A+B)$ \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9df7077",
   "metadata": {},
   "source": [
    "### Exercise 2.57\n",
    "\n",
    "Just apply 2.92 and 2.93 twice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79932656",
   "metadata": {},
   "source": [
    "### Exercise 2.58\n",
    "\n",
    "The expectation is the eigenvalue corresponding to $\\psi$ and the variance is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3fad8b",
   "metadata": {},
   "source": [
    "### Exercise 2.59\n",
    "\n",
    "$E[X] = \\bra{0}X\\ket{0} = \\braket{0}{1} = 0$\n",
    "\n",
    "$std(X) = \\left(\\bra{0}X^2\\ket{0} - E[X]^2\\right)^\\frac{1}{2} = 1$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25dbbe",
   "metadata": {},
   "source": [
    "### Exercise 2.60\n",
    "\n",
    "Let $\\Sigma := \\sum_{i=1}^3 v_i \\sigma_i := v\\cdot\\sigma$\n",
    "\n",
    "1) To show the eigenvalues are $\\pm 1$ it suffices to show $\\Sigma^2 = I$\n",
    "\n",
    "$$\n",
    "\\Sigma^2 = \\sum_{ij}v_i v_j \\sigma_i \\sigma_j = \\sum_i v_i^2 \\sigma_i^2 + \\sum_{i\\neq j}v_i v_j \\sigma_i \\sigma_j = \n",
    "\\sum_i v_i^2 + \\sum_{i\\neq j} \\epsilon_{ij}^k\\sigma_k\n",
    "$$\n",
    "\n",
    "The first terms sums to the identity since v is a unit vector and the second term cancels out, so $\\Sigma^2 = I$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d1e054",
   "metadata": {},
   "source": [
    "2) To show that P is a projector we must show $P^2 = P$.\n",
    "\n",
    "$$\n",
    "P^2 = \\frac{1}{4}(I+\\sum_i v_i \\sigma_i)(I+\\sum_j v_j \\sigma_j) = \n",
    " \\frac{1}{4}\\left(I + 2\\sum_i v_i \\sigma_i + \\sum_{i} v_i^2 +  \\sum_{i\\neq j} \\epsilon_{ij}^k\\sigma_k \\right) =\\\\\n",
    " \\frac{1}{4}\\left(2I + 2 v\\cdot\\sigma \\right) = \\frac{I + v\\cdot\\sigma}{2} = P\n",
    "$$\n",
    "\n",
    "The calculation for the minus sign version is the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ab4aef",
   "metadata": {},
   "source": [
    "3) To show thet P projects on the eigenspace spanned by the eigenvectors, it suffices to show that every eigenvector is projected onto the same subspace.\n",
    "\n",
    "let $\\ket{x}$ be an eigenvector of $\\Sigma$ with eigenvalue 1\n",
    "\n",
    "$$\n",
    "(I+\\Sigma)\\ket{x} = 2\\ket{x}\n",
    "$$\n",
    "\n",
    "so it is in the same subspace. The same result follows for the the other projector and an eigenvector of -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91503dbc",
   "metadata": {},
   "source": [
    "### Exercise 2.61\n",
    "\n",
    "VERIFY\n",
    "\n",
    "Probability = ${1+v_3}{2}$\n",
    "\n",
    "State = $(1+v_3)\\ket{0} + (v_1+iv_2)\\ket{1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aadccc9",
   "metadata": {},
   "source": [
    "### Exercise 2.62\n",
    "\n",
    "If $M_m = E_m$, then $M_m = M_m^\\dagger M_m$.\n",
    "\n",
    "Taking the transpose of both sides\n",
    "\n",
    "$M_m^\\dagger = M_m^\\dagger M_m = M_m$\n",
    "\n",
    "from which we conclude $M_m^2 = M_m$, therefore it is a projection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48816c",
   "metadata": {},
   "source": [
    "### Exercise 2.65\n",
    "\n",
    "Apply H to these states to get $\\ket{1}$ and $\\ket{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28acdbe4",
   "metadata": {},
   "source": [
    "### Exercise 2.66\n",
    "\n",
    "$X_1 Z_2\\ket{00} = \\ket{10}$\n",
    "$X_1 Z_2\\ket{11} = -\\ket{01}$\n",
    "\n",
    "so $X_1 Z_2\\ket{\\psi} = \\frac{\\ket{10}-\\ket{01}}{\\sqrt{2}}$\n",
    "\n",
    "and since Bell states are orthonormal the inner product of this with $\\psi$ is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ca829",
   "metadata": {},
   "source": [
    "### Exercise 2.67\n",
    "\n",
    "The idea is to extend the $m \\times m$ matrix $U$ to an $n \\times n$ matrix \n",
    "$\\begin{bmatrix}U & 0\\\\ 0 & I\\end{bmatrix}$\n",
    "\n",
    "First, start by choosing an orthonormal basis $e_1, \\ldots, e_n$ such that $e_1, \\ldots, e_m$ are in $W$ and the remaining are in $W^\\perp$.\n",
    "\n",
    "Then note that the images $\\epsilon_j = Ue_j$ are also orthonormal by the inner product preserving property of $U$:\n",
    "$\\braket{\\epsilon_i}{\\epsilon_j} = \\braket{Ue_i}{Ue_j} \\braket{e_i}{e_j} = \\delta_{ij}$ \n",
    "\n",
    "Using the Gram-Schmidt process extend $\\epsilon_1, \\ldots \\epsilon_m$ to a full orthonormal basis that spans $Im(U)^\\perp$.\n",
    "\n",
    "The for a vector $v = \\sum_i v^i e_i$, define $U'v \\equiv \\sum_i v^i \\epsilon_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4da1a",
   "metadata": {},
   "source": [
    "### Exercise 2.68\n",
    "\n",
    "Let $\\ket{a} = a_1\\ket{0}+a_2\\ket{1}$, $\\ket{b} = b_1\\ket{0}+b_2\\ket{1}$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\ket{a}\\otimes \\ket{b} = ( a_1\\ket{0}+a_2\\ket{1})\\otimes (b_1\\ket{0}+b_2\\ket{1}) =\n",
    "a_1 b_1\\ket{00}+a_2 b_1\\ket{10}+a_1 b_2\\ket{01}+a_2 b_2 \\ket{11}\n",
    "$$\n",
    "\n",
    "So we must have $a_1 b_1 = a_2 b_2 = 1$ and  $a_1 b_2 = a_2 b_1 = 0$, which is impossible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb415fe-14a2-487b-a9c1-8d7c0c7d5c6d",
   "metadata": {},
   "source": [
    "### Problem 2.1\n",
    "\n",
    "I will show the result for analytic functions. First observe that $(n\\cdot \\sigma)^2 = I$, which can be shown using the fact that $|n|^2 = 1$ and the anticommutator of any two Pauli matrices is 0.\n",
    "\n",
    "We also observe that every function $f(\\theta)$ can be decoposed as the sum of an even part $\\frac{f(\\theta) + f(-\\theta)}{2}$\n",
    "and an odd part $\\frac{f(\\theta) - f(-\\theta)}{2}$\n",
    "\n",
    "We Taylor expand $f(\\theta n\\cdot \\sigma)$ around 0:\n",
    "\n",
    "$$\n",
    "f(\\theta n\\cdot \\sigma) = \\sum_n \\frac{f^{(n)}(0)\\theta^n}{n!} (n\\cdot \\sigma)^n = \n",
    "\\sum_{even}\\frac{f^{(n)}(0)\\theta^n}{n!} I + \\sum_{odd}\\frac{f^{(n)}(0)\\theta^n}{n!}n\\cdot \\sigma\n",
    "$$\n",
    "\n",
    "similarily\n",
    "\n",
    "$$\n",
    "f(-\\theta n\\cdot \\sigma) = \n",
    "\\sum_{even}\\frac{f^{(n)}(0)\\theta^n}{n!} I - \\sum_{odd}\\frac{f^{(n)}(0)\\theta^n}{n!}n\\cdot \\sigma\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a5aa9-c97f-4f25-939c-4d4981680cd9",
   "metadata": {},
   "source": [
    "By summing the expressions above, the even part of $f(\\theta n\\cdot \\sigma)$  is given by \n",
    "\n",
    "$$\n",
    "\\frac{f(\\theta n\\cdot \\sigma) + f(-\\theta n\\cdot \\sigma)}{2} = \\frac{f^{(n)}(0)\\theta^n}{2n!} I = \\frac{f(\\theta)+f(-\\theta)}{2}I\n",
    "$$\n",
    "\n",
    "and the odd part \n",
    "\n",
    "$$\n",
    "\\frac{f(\\theta n\\cdot \\sigma) - f(-\\theta n\\cdot \\sigma)}{2} = \\sum_{odd}\\frac{f^{(n)}(0)\\theta^n}{2n!}n\\cdot \\sigma\n",
    "= \\frac{f(\\theta)-f(-\\theta)}{2}n\\cdot \\sigma\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93a69b0-6ed2-4df6-8aa3-6242763ed6c3",
   "metadata": {},
   "source": [
    "The whole function is obtained by adding the even and odd parts\n",
    "\n",
    "$$\n",
    "f(\\theta n\\cdot \\sigma) = \\frac{f(\\theta)+f(-\\theta)}{2}I + \\frac{f(\\theta)-f(-\\theta)}{2}n\\cdot \\sigma\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b6eab9-676f-4c5d-8414-71afb044a7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physics-with-friends",
   "language": "python",
   "name": "physics-with-friends"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
